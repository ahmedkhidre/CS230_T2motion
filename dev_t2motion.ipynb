{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6c4778",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b01def79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import mixed_precision\n",
    "#from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from matplotlib.animation import FuncAnimation \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "import copy\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ddefa",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d19b7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "from_scratch=False # True: start fresh, False: resume from checkpoint\n",
    "# Define model saving paths\n",
    "SAVE_Full_MODEL_PATH = f\"/Users/akhidre/pubgit/CS230_T2motion/models/full_checkpoint.keras\" # use this for full model checkpoint\n",
    "\n",
    "# TensorBoard directory\n",
    "\n",
    "log_dir = f\"/Users/akhidre/pubgit/CS230_T2motion/fit/{time_stamp}/\"\n",
    "\n",
    "#define data destination\n",
    "TRAIN_NPZ = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/paired_text_motion.npz\"\n",
    "TEST_NPZ  = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/paired_text_motion_val.npz\"\n",
    "NORM_STATS = \"motion_norm_stats.npz\"   # if exists, used; otherwise computed from train npz\n",
    "\n",
    "MOTION_LEN = 200         # fixed length for MLP outputs (frames)\n",
    "NUM_JOINTS = 22\n",
    "COORDS = 3\n",
    "OUTPUT_DIM = MOTION_LEN * NUM_JOINTS * COORDS\n",
    "\n",
    "MAX_TRAIN_SAMPLES =0    # 0 = use all; otherwise use first N pairs\n",
    "MAX_TEST_SAMPLES = 0   # 0 = use all; otherwise use first N pairs\n",
    "\n",
    "USE_NORMALIZATION = False   #normalize data to zero mean and unity variance\n",
    "\n",
    "# Training hyperparams\n",
    "USE_GPU = False\n",
    "USE_LR_SCHEDULER = False\n",
    "USE_EARLY_STOPPING = False\n",
    "USE_LR_LOGGER = False  # only if you added the logger\n",
    "\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 75\n",
    "LEARNING_RATE = 1e-4\n",
    "HIDDEN_DIMS = [1024, 2048, 8192]  # list: number of neurons per hidden Dense layer\n",
    "\n",
    "# Loss options\n",
    "USE_VELOCITY_LOSS = True\n",
    "LAMBDA_VEL = 1\n",
    "USE_WEIGHT_DECAY = True\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e8471",
   "metadata": {},
   "source": [
    "### Utilities Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86335104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz_pairs(npz_path, max_samples=0):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    z_texts = data[\"z_texts\"]   # shape (N, 384)\n",
    "    motions = data[\"motions\"]   # dtype=object, each entry (T, J, 3)\n",
    "    motion_ids = data[\"motion_ids\"] if \"motion_ids\" in data.files else None\n",
    "\n",
    "    if max_samples and max_samples > 0:\n",
    "        z_texts = z_texts[:max_samples]\n",
    "        motions = motions[:max_samples]\n",
    "        if motion_ids is not None:\n",
    "            motion_ids = motion_ids[:max_samples]\n",
    "\n",
    "    return z_texts, motions, motion_ids\n",
    "\n",
    "def filter_valid_motions(z_list, motions_list, ids_list=None,\n",
    "                         num_joints=22, coords=3):\n",
    "    \"\"\"\n",
    "    Filters out invalid motion sequences that do not match (T, num_joints, coords).\n",
    "\n",
    "    Returns:\n",
    "        valid_z_list, valid_motions_list, valid_ids_list (or None if no ids)\n",
    "    \"\"\"\n",
    "    valid_z = []\n",
    "    valid_motions = []\n",
    "    valid_ids = [] if ids_list is not None else None\n",
    "\n",
    "    for idx, (z, m) in enumerate(zip(z_list, motions_list)):\n",
    "        arr = np.array(m)\n",
    "\n",
    "        # Check dimensionality\n",
    "        if arr.ndim != 3:\n",
    "            print(f\"[Filter] Skipping sample at index={idx}, shape={arr.shape} (not 3D)\")\n",
    "            continue\n",
    "\n",
    "        # Check joint and coordinate dimensions\n",
    "        if arr.shape[1] != num_joints or arr.shape[2] != coords:\n",
    "            print(f\"[Filter] Skipping sample at index={idx}, shape={arr.shape} (bad joint dims)\")\n",
    "            continue\n",
    "\n",
    "        # Keep sample\n",
    "        valid_z.append(z)\n",
    "        valid_motions.append(arr)\n",
    "\n",
    "        if ids_list is not None:\n",
    "            valid_ids.append(ids_list[idx])\n",
    "\n",
    "    if ids_list is not None:\n",
    "        return np.array(valid_z, dtype=np.float32), valid_motions, valid_ids\n",
    "    else:\n",
    "        return np.array(valid_z, dtype=np.float32), valid_motions, None\n",
    "\n",
    "def compute_mean_std_from_train_motions(motions, save_path=None):\n",
    "    \"\"\"\n",
    "    Compute per-coordinate mean and std for a list of motion sequences.\n",
    "\n",
    "    Args:\n",
    "        motions: list or object array of motions, each shape (T, J, 3)\n",
    "        save_path: str or None, optional path to save stats as .npz\n",
    "\n",
    "    Returns:\n",
    "        mean: np.array of shape (3,)\n",
    "        std: np.array of shape (3,)\n",
    "    \"\"\"\n",
    "    coords_list = []\n",
    "    for m in motions:\n",
    "        coords_list.append(m.reshape(-1, 3))\n",
    "    all_coords = np.concatenate(coords_list, axis=0)\n",
    "    mean = np.mean(all_coords, axis=0).astype(np.float32)\n",
    "    std  = np.std(all_coords, axis=0).astype(np.float32) + 1e-8\n",
    "\n",
    "    if save_path is not None:\n",
    "        np.savez(save_path, mean=mean, std=std)\n",
    "        print(f\"Saved motion normalization stats to {save_path}\")\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "def pad_or_truncate_motion(motion, target_len=MOTION_LEN):\n",
    "    T, J, C = motion.shape\n",
    "    if T == target_len:\n",
    "        return motion.astype(np.float32)\n",
    "    if T > target_len:\n",
    "        return motion[:target_len].astype(np.float32)\n",
    "    # T < target_len: pad with zeros at end\n",
    "    pad_len = target_len - T\n",
    "    last_frame = motion[-1][None, :, :]  # shape (1, J, C)\n",
    "    pad = np.repeat(last_frame, pad_len, axis=0)  # repeat last frame\n",
    "    return np.concatenate([motion.astype(np.float32), pad], axis=0)\n",
    "\n",
    "def normalize_motion(motion, mean, std):\n",
    "    # motion: (T, J, 3) -> broadcast mean/std over joints/frames\n",
    "    return (motion - mean) / std\n",
    "\n",
    "def denormalize_motion(motion_norm, mean, std):\n",
    "    return motion_norm * std + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c590552",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2849de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading train npz:\", TRAIN_NPZ)\n",
    "z_train, motions_train, ids_train = load_npz_pairs(TRAIN_NPZ, max_samples=MAX_TRAIN_SAMPLES)\n",
    "print(\"Filtering training motions...\")\n",
    "z_train, motions_train, ids_train = filter_valid_motions(z_train, motions_train, ids_train)\n",
    "print(\"Final train samples:\", len(z_train))\n",
    "\n",
    "print(\"Loading test npz:\", TEST_NPZ)\n",
    "z_test, motions_test, ids_test = load_npz_pairs(TEST_NPZ, max_samples=MAX_TEST_SAMPLES)\n",
    "\n",
    "print(\"Filtering test motions...\")\n",
    "z_test, motions_test, ids_test = filter_valid_motions(z_test, motions_test, ids_test)\n",
    "print(\"Final test samples:\", len(z_test))\n",
    "\n",
    "\n",
    "print(\"Train captions:\", z_train.shape)\n",
    "print(\"Train motions count:\", len(motions_train))\n",
    "print(\"Train ids_count:\", len(ids_train))\n",
    "print(\"Test captions:\", z_test.shape)\n",
    "print(\"Test motions count:\", len(motions_test))\n",
    "print(\"Test ids_count:\", len(ids_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471bfdcd",
   "metadata": {},
   "source": [
    "### Compute data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34216840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing normalization stats from training motions...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(NORM_STATS):\n",
    "    stats = np.load(NORM_STATS)\n",
    "    mean = stats[\"mean\"]   # shape (3,)\n",
    "    std = stats[\"std\"]\n",
    "    print(\"Loaded normalization stats from\", NORM_STATS, \"mean:\", mean, \"std:\", std)\n",
    "else:\n",
    "    print(\"Computing normalization stats from training motions...\")\n",
    "    # compute and save in one call\n",
    "    mean, std = compute_mean_std_from_train_motions(motions_train)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e8e57e",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e720518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_xy(z_list, motions_objectlist, mean, std, motion_len=MOTION_LEN):\n",
    "    N = len(z_list)\n",
    "    X = np.array(z_list, dtype=np.float32)   # (N, 384)\n",
    "    Y = np.zeros((N, motion_len, NUM_JOINTS, COORDS), dtype=np.float32)\n",
    "    for i, m in enumerate(motions_objectlist):\n",
    "        m_fixed = pad_or_truncate_motion(m, target_len=motion_len)\n",
    "        if USE_NORMALIZATION:\n",
    "            m_out = normalize_motion(m_fixed, mean, std)\n",
    "        else:\n",
    "            m_out = m_fixed  # leave as-is\n",
    "        Y[i] = m_out\n",
    "    # flatten Y for MLP regression target\n",
    "    Y_flat = Y.reshape(N, -1).astype(np.float32)\n",
    "    return X, Y_flat, Y  # also return 3D Y if needed\n",
    "\n",
    "print(\"Preparing training tensors...\")\n",
    "X_train, Y_train_flat, Y_train_3d = prepare_xy(z_train, motions_train, mean, std)\n",
    "print(\"Preparing test tensors...\")\n",
    "X_test, Y_test_flat, Y_test_3d = prepare_xy(z_test, motions_test, mean, std)\n",
    "\n",
    "print(\"Shapes -> X_train:\", X_train.shape, \"Y_train_flat:\", Y_train_flat.shape)\n",
    "print(\"Shapes -> X_test :\", X_test.shape, \"Y_test_flat :\", Y_test_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702d03a",
   "metadata": {},
   "source": [
    "### MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d010d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_Motion_Decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_text (InputLayer)         [(None, 384)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              394240    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8192)              16785408  \n",
      "                                                                 \n",
      " output_flat (Dense)         (None, 13200)             108147600 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127426448 (486.09 MB)\n",
      "Trainable params: 127426448 (486.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # Clear any existing session\n",
    "if USE_GPU:\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Mixed precision policy:\", mixed_precision.global_policy())\n",
    "# input and model definition\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1],), dtype=tf.float32, name=\"z_text\")\n",
    "x = inputs\n",
    "for i, h in enumerate(HIDDEN_DIMS):\n",
    "    x = tf.keras.layers.Dense(h, activation=\"relu\", name=f\"dense_{i+1}\")(x)\n",
    "# final linear layer -> output_dim\n",
    "# IMPORTANT: cast final output to float32 for stable losses\n",
    "outputs_flat = tf.keras.layers.Dense(OUTPUT_DIM, activation=None, name=\"output_flat\", dtype=\"float32\")(x)\n",
    "\n",
    "# Optionally reshape inside model (but we will train with flattened y)\n",
    "# outputs_reshaped = tf.keras.layers.Reshape((MOTION_LEN, NUM_JOINTS, COORDS))(outputs_flat)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs_flat, name=\"MLP_Motion_Decoder\")\n",
    "model.summary()\n",
    "\n",
    "# ---------------------------\n",
    "# Loss: MSE + optional velocity loss + optional weight decay\n",
    "# ---------------------------\n",
    "def velocity_loss_from_flat(y_true_flat, y_pred_flat, motion_len=MOTION_LEN):\n",
    "    # y_true_flat, y_pred_flat: (batch, motion_len * J * C)\n",
    "    # reshape\n",
    "    batch = tf.shape(y_true_flat)[0]\n",
    "    y_true = tf.reshape(y_true_flat, (batch, motion_len, NUM_JOINTS, COORDS))\n",
    "    y_pred = tf.reshape(y_pred_flat, (batch, motion_len, NUM_JOINTS, COORDS))\n",
    "    # velocities: difference over time axis\n",
    "    v_true = y_true[:,1:] - y_true[:,:-1]\n",
    "    v_pred = y_pred[:,1:] - y_pred[:,:-1]\n",
    "    return tf.reduce_mean(tf.square(v_pred - v_true))\n",
    "\n",
    "# Custom training step via compile with custom loss wrapper\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mse = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "    if USE_VELOCITY_LOSS:\n",
    "        vel = velocity_loss_from_flat(y_true, y_pred)\n",
    "        loss_val = mse + LAMBDA_VEL * vel\n",
    "    else:\n",
    "        loss_val = mse\n",
    "    return loss_val\n",
    "\n",
    "optimizer = AdamW(learning_rate=LEARNING_RATE,weight_decay=WEIGHT_DECAY) #<-- gradient clipping\n",
    "model.compile(optimizer=optimizer, loss=custom_loss, metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c614f4",
   "metadata": {},
   "source": [
    "### Training callbacks and monitors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a42bb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,   # enables gradients & weights monitoring\n",
    "    write_graph=False\n",
    ")\n",
    "\n",
    "# Reduce LR on Plateau\n",
    "reduceLR_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=7,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save best weights only\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=SAVE_Full_MODEL_PATH,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "class LRTensorBoard(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir):\n",
    "        super().__init__()\n",
    "        self.file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        with self.file_writer.as_default():\n",
    "            tf.summary.scalar(\"learning_rate\", lr, step=epoch)\n",
    "\n",
    "lr_logger = LRTensorBoard(log_dir=log_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "callbacks_list = [tensorboard_cb, checkpoint_cb]\n",
    "\n",
    "if USE_LR_SCHEDULER:\n",
    "    callbacks_list.append(reduceLR_cb)\n",
    "\n",
    "if USE_EARLY_STOPPING:\n",
    "    callbacks_list.append(earlystop_cb)\n",
    "\n",
    "# Optional: add LR logger if you use it\n",
    "if USE_LR_LOGGER:\n",
    "    callbacks_list.append(lr_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761c5a8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not from_scratch and os.path.exists(SAVE_Full_MODEL_PATH):\n",
    "    print(\"Loading model (weights or full checkpoint)\")\n",
    "    model=tf.keras.models.load_model(SAVE_Full_MODEL_PATH,custom_objects={'custom_loss': custom_loss})\n",
    "else:\n",
    "    print(\"training from scratch.\")\n",
    "    pass  # do nothing, use existing model\n",
    "\n",
    "tf.config.run_functions_eagerly(False)  # for performance\n",
    "history = model.fit(\n",
    "    X_train, Y_train_flat,\n",
    "    validation_data=(X_test, Y_test_flat),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "# plot loss curves\n",
    "# ----------------------------\n",
    "# 1) Combined loss plot\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Combined Loss (Pose + Velocity)')\n",
    "plt.title('Training / Validation Combined Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Pose-only MSE plot\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['mse'], label='train_mse')\n",
    "plt.plot(history.history['val_mse'], label='val_mse')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Pose MSE')\n",
    "plt.title('Training / Validation Pose MSE (Position Only)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89077a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21dcd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(X_test, Y_test_flat, batch_size=BATCH_SIZE, return_dict=True)\n",
    "print(\"Test metrics:\", test_metrics)\n",
    "\n",
    "# compute velocity loss separately if needed\n",
    "if USE_VELOCITY_LOSS:\n",
    "    preds_flat = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "    vel_loss_val = velocity_loss_from_flat(tf.constant(Y_test_flat), tf.constant(preds_flat))\n",
    "    print(\"Test velocity loss:\", float(vel_loss_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb4dde",
   "metadata": {},
   "source": [
    "### Run Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0 #sampling example\n",
    "\n",
    "motion_id = ids_test[sample_idx]\n",
    "print(\"Test motion ID:\", motion_id)\n",
    "\n",
    "\n",
    "z = X_test[sample_idx:sample_idx+1]\n",
    "pred_flat = model.predict(z)  # shape (1, OUTPUT_DIM)\n",
    "pred_3d = pred_flat.reshape(MOTION_LEN, NUM_JOINTS, COORDS)\n",
    "\n",
    "if USE_NORMALIZATION:\n",
    "    pred_real = denormalize_motion(pred_3d, mean, std)\n",
    "else:\n",
    "    pred_real = pred_3d\n",
    "\n",
    "print(\"Predicted motion final shape:\", pred_real.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2f4eb",
   "metadata": {},
   "source": [
    "### Animation of Generated Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc03f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose=copy.deepcopy(pred_real)\n",
    "#SMPL 22-joint skeleton\n",
    "edges = [\n",
    "    (0, 1), (1, 4), (4, 7), (7, 10),\n",
    "    (0, 2), (2, 5), (5, 8), (8, 11),\n",
    "    (0, 3), (3, 6), (6, 9), (9, 12), (12, 15),\n",
    "    (9, 13), (13, 16), (16, 18), (18, 20),\n",
    "    (9, 14), (14, 17), (17, 19), (19, 21),\n",
    "]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Create lines initially without data\n",
    "lines = [ax.plot([], [], [])[0] for _ in range(pose.shape[1] - 1)]\n",
    "ax.set(xlim3d=(-1, 3), xlabel='X')\n",
    "ax.set(ylim3d=(-1, 1), ylabel='Y')\n",
    "ax.set(zlim3d=(-1, 1), zlabel='Z')\n",
    "\n",
    "def init(): \n",
    "    ax.cla()\n",
    "    return ax,\n",
    "\n",
    "def update_lines(frame_num, pose, lines):\n",
    "    frame = pose[frame_num]\n",
    "    for n in range(len(lines)):\n",
    "        i, j = edges[n]\n",
    "        x = [frame[i, 0], frame[j, 0]]\n",
    "        y = [frame[i, 1], frame[j, 1]]\n",
    "        z = [frame[i, 2], frame[j, 2]]\n",
    "        lines[n].set_data_3d([z,x,y])\n",
    "    return lines\n",
    "\n",
    "ani = FuncAnimation(fig, update_lines, pose.shape[0], fargs=(pose, lines), interval=100)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ani.save(f'/Users/akhidre/pubgit/CS230_T2Motion/animations/generate_{motion_id}_{timestamp}.mp4', writer = 'ffmpeg', fps = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315a718",
   "metadata": {},
   "source": [
    "### Troubleshoot/Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9cbdef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF GPUs: []\n",
      "2.15.1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "tf.config.experimental.get_visible_devices()\n",
    "tf.config.list_logical_devices('GPU')\n",
    "\n",
    "os.path.exists(SAVE_Full_MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".My_HumanML3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
