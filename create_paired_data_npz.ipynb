{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d0ee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhidre/pubgit/.My_HumanML3D/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59e00b",
   "metadata": {},
   "source": [
    "### Encode all captions and save top .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "index_file = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/train.txt\"   # index file listing caption IDs\n",
    "base_path = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/texts\"   # folder containing the actual caption text files\n",
    "output_file = \"text_embeddings.npy\"\n",
    "batch_size = 8\n",
    "\n",
    "# --- LOAD MODEL ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# --- READ INDEX FILE ---\n",
    "with open(index_file, 'r') as f:\n",
    "    caption_paths = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"Found {len(caption_paths)} caption entries in index file\")\n",
    "\n",
    "# --- COLLECT CAPTIONS ---\n",
    "captions = []\n",
    "for path in tqdm(caption_paths, desc=\"Loading captions\"):\n",
    "    # ✅ Add .txt automatically if missing\n",
    "    if not path.endswith(\".txt\"):\n",
    "        path = path + \".txt\"\n",
    "\n",
    "    full_path = os.path.join(base_path, path)\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"⚠️ Skipping missing file: {full_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(full_path, 'r') as f:\n",
    "        # Remove metadata (after '#') and empty lines\n",
    "        lines = [l.strip().split('#')[0] for l in f if l.strip()]\n",
    "        captions.extend(lines)\n",
    "\n",
    "print(f\"✅ Total captions collected: {len(captions)}\")\n",
    "\n",
    "# --- GENERATE EMBEDDINGS ---\n",
    "embeddings = model.encode(captions, batch_size=batch_size, show_progress_bar=True)\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# --- SAVE TO DISK ---\n",
    "np.save(output_file, embeddings)\n",
    "print(f\"✅ Saved {embeddings.shape} embeddings to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802553c",
   "metadata": {},
   "source": [
    "### Pairing encoded text caption (z-text) and motion and save to .npz\n",
    "user input how many files want to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83bd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# --- CONFIG ---\n",
    "index_file = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/val.txt\"\n",
    "motion_path = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/new_joints\"\n",
    "caption_path = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/texts\"\n",
    "output_file = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/paired_text_motion_val.npz\"\n",
    "max_files =[]   # optional, for testing\n",
    "\n",
    "# --- LOAD MODEL ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# --- READ INDEX FILE ---\n",
    "with open(index_file, 'r') as f:\n",
    "    motion_ids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "if max_files:\n",
    "    motion_ids = motion_ids[:max_files]\n",
    "\n",
    "paired_data = {\"z_texts\": [], \"motions\": [], \"motion_ids\": []}\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "for motion_id in tqdm(motion_ids, desc=\"Pairing text and motion\"):\n",
    "    motion_file = os.path.join(motion_path, f\"{motion_id}.npy\")\n",
    "    caption_file = os.path.join(caption_path, f\"{motion_id}.txt\")\n",
    "\n",
    "    if not (os.path.exists(motion_file) and os.path.exists(caption_file)):\n",
    "        print(f\"⚠️ Skipping missing pair: {motion_id}\")\n",
    "        continue\n",
    "\n",
    "    # Load motion\n",
    "    motion = np.load(motion_file)  # shape: (T, 22, 3)\n",
    "    \n",
    "    # Load captions\n",
    "    with open(caption_file, 'r') as f:\n",
    "        captions = [l.strip().split('#')[0] for l in f if l.strip()]\n",
    "\n",
    "    # Compute embeddings\n",
    "    z_texts = model.encode(captions, show_progress_bar=False)\n",
    "\n",
    "    # Store all captions from this motion file\n",
    "    for z in z_texts:\n",
    "        paired_data[\"z_texts\"].append(z)\n",
    "        paired_data[\"motions\"].append(motion)\n",
    "        paired_data[\"motion_ids\"].append(motion_id)\n",
    "\n",
    "# --- SAVE COMPACTLY ---\n",
    "np.savez_compressed(output_file,\n",
    "                    z_texts=np.array(paired_data[\"z_texts\"], dtype=np.float32),\n",
    "                    motions=np.array(paired_data[\"motions\"], dtype=object),\n",
    "                    motion_ids=np.array(paired_data[\"motion_ids\"]))\n",
    "\n",
    "print(f\"✅ Saved paired text-motion dataset to {output_file}\")\n",
    "print(f\"Total pairs: {len(paired_data['z_texts'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3770a4",
   "metadata": {},
   "source": [
    "### Loading paired texted embedding and motion sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed82c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_text shape: (384,)\n",
      "motion shape: (199, 22, 3)\n",
      "(69896, 384)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"/Users/akhidre/pubgit/HumanML3D/HumanML3D/paired_text_motion.npz\", allow_pickle=True)\n",
    "z_texts = data[\"z_texts\"]\n",
    "motions = data[\"motions\"]\n",
    "\n",
    "# Example access:\n",
    "i = 22\n",
    "print(\"z_text shape:\", z_texts[i].shape)\n",
    "\n",
    "print(\"motion shape:\", motions[i].shape)\n",
    "print(z_texts.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a88b4",
   "metadata": {},
   "source": [
    "### Check maximum frames in HumanML3D dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab75409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "motion_dir = \"/Users/akhidre/pubgit/HumanML3D/HumanML3D/new_joints\"\n",
    "\n",
    "max_len = 0\n",
    "files_with_max = []\n",
    "\n",
    "# Loop through all motion files\n",
    "for fname in os.listdir(motion_dir):\n",
    "    if not fname.endswith(\".npy\"):\n",
    "        continue\n",
    "    motion = np.load(os.path.join(motion_dir, fname))\n",
    "    T = motion.shape[0]\n",
    "    \n",
    "    if T > max_len:\n",
    "        max_len = T\n",
    "        files_with_max = [fname]\n",
    "    elif T == max_len:\n",
    "        files_with_max.append(fname)\n",
    "\n",
    "print(f\"Maximum number of frames: {max_len}\")\n",
    "print(\"Files with maximum frames:\")\n",
    "for f in files_with_max:\n",
    "    print(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
